{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNfcA9Ci+JykpJm1LexwBmQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ndIUvbw8iuf8"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["from tensorflow.keras.layers import Input,Dense,Flatten\n","from tensorflow.keras.applications.vgg16 import VGG16 as PretrainedModel,preprocess_input\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD,Adam\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import sys, os"],"metadata":{"id":"u4PgDOBki-MP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data from: https://mmspg.epfl.ch/dowloads/food-image-datasets/\n","!wget --passive-ftp --prefer-family=ipv4 --ftp-user FoodImage@grebvm2.epfl.ch \\\n"," --ftp-password Cahclmoo -nc ftp://tremplin.epfl.ch/Food-5K.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"erqIBbiCi_v6","outputId":"642d2610-d29c-4e16-d8c0-0414dfc722e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-02-28 12:54:16--  ftp://tremplin.epfl.ch/Food-5K.zip\n","           => ‘Food-5K.zip’\n","Resolving tremplin.epfl.ch (tremplin.epfl.ch)... 128.178.218.41, 2001:620:618:1da:7:80b2:da01:3\n","Connecting to tremplin.epfl.ch (tremplin.epfl.ch)|128.178.218.41|:21... connected.\n","Logging in as FoodImage@grebvm2.epfl.ch ... \n","Error in server response, closing control connection.\n","Retrying.\n","\n","--2025-02-28 12:56:25--  ftp://tremplin.epfl.ch/Food-5K.zip\n","  (try: 2) => ‘Food-5K.zip’\n","Connecting to tremplin.epfl.ch (tremplin.epfl.ch)|128.178.218.41|:21... connected.\n","Logging in as FoodImage@grebvm2.epfl.ch ... "]}]},{"cell_type":"code","source":["! unzip -qq -o Food-5K.zip"],"metadata":{"id":"JVKabr9SjCDR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"7tjAV3ScjGi0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls training"],"metadata":{"id":"QPHh8oN7jHv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# look at an image for fun\n","plt.imshow(image.load_img('training/0_100.jpg'))\n","plt.show()"],"metadata":{"id":"Q-XsY4injI98"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Food images start with 1, non-food images start with 0\n","plt.imshow(image.load_img('training/1_100.jpg'))\n","plt.show()"],"metadata":{"id":"VrIYEUiQjL9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!mkdir data"],"metadata":{"id":"JYxsLoYmjNwQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Make directories to store the data Keras-style\n","!mkdir data/train\n","!mkdir data/test\n","!mkdir data/train/nonfood\n","!mkdir data/train/food\n","!mkdir data/test/nonfood\n","!mkdir data/test/food"],"metadata":{"id":"S4cRidLDjQQC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Move the images\n","# Note we will consider 'training' to be the train set\n","#      'validation' folder will be the test set\n","#      ignore the 'evaluation' set\n","!mv training/0*.jpg data/train/nonfood\n","!mv training/1*.jpg data/train/food\n","!mv validation/0*.jpg data/test/nonfood\n","!mv validation/1*.jpg data/test/food"],"metadata":{"id":"ItMVdzsZjRdR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_path = 'data/train'\n","valid_path = 'data/test'"],"metadata":{"id":"e5q--EhkjT-_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# These images are pretty big and of different sizes\n","# Let's load them all in as the same (smaller) size\n","IMAGE_SIZE =[200,200]"],"metadata":{"id":"1Ys-o8qgjVp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# useful for getting number of files\n","image_files = glob(train_path + '/*/*.jpg')\n","valid_image_files = glob(valid_path + '/*/*.jpg')"],"metadata":{"id":"ii0PKczzjW8-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# useful for getting number of classes\n","folders = glob(train_path + '/*')\n","folders"],"metadata":{"id":"v27BZxe5jdfN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# look at an image for fun\n","plt.imshow(image.load_img(np.random.choice(image_files)))\n","plt.show()"],"metadata":{"id":"0gxrB1yHjfBV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ptm = PretrainedModel(\n","    input_shape=IMAGE_SIZE + [3],\n","    weights='imagenet',\n","    include_top=False)"],"metadata":{"id":"H3hv5AQEjgZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# map the data into feature vector\n","x = Flatten()(ptm.output)"],"metadata":{"id":"0v4n6oOkjsn1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a model object\n","model = Model(inputs=ptm.input, outputs=x)"],"metadata":{"id":"lPKRg3Xej0jH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#view the structure of the model\n","model.summary()"],"metadata":{"id":"nzPEyVDTj6qe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create an instance of ImageDataGenerator\n","gen = ImageDataGenerator(preprocessing_function=preprocess_input)"],"metadata":{"id":"LVzf83uPj9FN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 128\n","\n","# create generators\n","train_generator = gen.flow_from_directory(\n","    train_path,\n","    target_size=IMAGE_SIZE,\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","valid_generator = gen.flow_from_directory(\n","    valid_path,\n","    target_size=IMAGE_SIZE,\n","    batch_size=batch_size,\n","    class_mode='binary')"],"metadata":{"id":"Uj9USi_3kQSk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Ntrain = len(image_files)\n","Nvalid = len(valid_image_files)\n","\n","# Figure out the output size\n","feat = model.predict(np.random.random([1] + IMAGE_SIZE[3]))\n","D = feat.shape[1]\n","\n","X_train = np.zeros((Ntrain, D))\n","Y_train = np.zeros(Ntrain)\n","X_valid = np.zeros((Nvalid, D))\n","Y_valid = np.zeros(Nvalid)"],"metadata":{"id":"9BBtjH8BkogJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# populate X_train and Y_train\n","i = 0\n","for x,y in train_generator:\n","  # get features\n","  features = model.predict(x)\n","\n","  # size of the batch (may not always be batch_size)\n","  sz = len(y)\n","\n","  # assing to X_train and Y_train\n","  X_train[i:i+sz] = features\n","  Y_train[i:i+sz] = y\n","\n","  # increment i\n","  i +=sz\n","  print(i)\n","\n","  if i>= Ntrain:\n","    print('breaking now')\n","    break\n","print(i)"],"metadata":{"id":"DSHKhONSlRxC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# populate X_valid and Y_valid\n","i = 0\n","for x,y in train_generator:\n","  # get features\n","  features = model.predict(x)\n","\n","  # size of the batch (may not always be batch_size)\n","  sz = len(y)\n","\n","  # assing to X_valid and Y_valid\n","  X_valid[i:i+sz] = features\n","  Y_valid[i:i+sz] = y\n","\n","  # increment i\n","  i +=sz\n","\n","\n","  if i>= Nvalid:\n","    print('breaking now')\n","    break\n","print(i)"],"metadata":{"id":"-IbANgGNmO_c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.max(), X_train.min()"],"metadata":{"id":"cQqYpxjGm4Ne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\n","\n","scaler = StandardScaler()\n","\n","X_train2 = scaler.fit_transform(X_train)\n","X_valid2 = scaler.transform(X_valid)"],"metadata":{"id":"OspPbOm1nBWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Try the built-in logistic regression\n","\n","from sklearn.linear_model import LogisticRegression\n","logr = LogisticRegression()\n","logr.fit(X_train2, Y_train)\n","print(logr.score(X_train2, Y_train))\n","print(logr.score(X_valid2, Y_valid))"],"metadata":{"id":"Pm4-wtcCnTYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Do logistic regression in Tensorflow\n","\n","i = Input(shape=(D,))\n","x = Dense(1,activation='sigmoid')(i)\n","linearmodel = Model(i, x)"],"metadata":{"id":"HsOFMjFWnnF9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lenearmodel.compile(\n","    loss='binary_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")"],"metadata":{"id":"4DTHGj1ioDny"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Can try both normalized and unnormalized data\n","r = linearmodel.fit(\n","    X_train, Y_train,\n","    validation_data=(X_valid, Y_valid),\n","    epochs=10,\n","    batch_size=128\n",")"],"metadata":{"id":"IKPXIteXoIU8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loss\n","plt.plot(r.history['loss'], label='loss')\n","plt.plot(r.history['val_loss'], label='val_loss')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"RRzBtSoboW9F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accuracies\n","plt.plot(r.history['accuracy'], label='train acc')\n","plt.plot(r.history['val_accuracy'], label='val acc')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"_fCKukjQobM-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"65mB4wsVok81"},"execution_count":null,"outputs":[]}]}